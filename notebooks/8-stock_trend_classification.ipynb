{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-16T15:36:03.995919800Z",
     "start_time": "2024-05-16T15:35:57.764510200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from datasets.SP100Stocks import SP100Stocks\n",
    "from notebooks.models import TGCN, A3TGCN, DCGNN, train, measure_accuracy, get_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stock trend classification\n",
    "The goal of this task is to classify the stock movement $n$ weeks ahead as a binary up/down trend, based on historical data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c131dcf02f1f4676"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the data\n",
    "The data from the custom PyG dataset for forecasting is loaded into a PyTorch dataloader.\n",
    "A \"transform\" is applied to change the targets `y` of the dataset to a binary buy/sell class instead of the close price. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d226612314d578cf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def future_close_price_to_buy_sell_class(sample: Data):\n",
    "\t\"\"\"\n",
    "\tTransforms the target y to a binary buy (1) if the stock return two weeks ahead was higher that the average market return, else sell (0)\n",
    "\t:param sample: Data sample\n",
    "\t:return: The transformed sample\n",
    "\t\"\"\"\n",
    "\tmarket_return = ((sample.close_price_y[:, -1] - sample.close_price[:, -1]) / sample.close_price[:, -1]).mean()\n",
    "\tsample.returns = ((sample.close_price_y[:, -1] - sample.close_price[:, -1]) / sample.close_price[:, -1]).unsqueeze(1)\n",
    "\tsample.market_return = market_return\n",
    "\tsample.y = (sample.returns >= 0).float()\n",
    "\treturn sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T15:36:04.008654700Z",
     "start_time": "2024-05-16T15:36:03.999216300Z"
    }
   },
   "id": "5e3cb82e3e8111d2",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": "(SP100Stocks(1187),\n Data(x=[100, 8, 25], edge_index=[2, 524], y=[100, 1], edge_weight=[524], close_price=[100, 25], close_price_y=[100, 5], returns=[100, 1], market_return=-0.01072738878428936))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks_ahead = 1\n",
    "\n",
    "dataset = SP100Stocks(future_window=weeks_ahead * 5, force_reload=True, transform=future_close_price_to_buy_sell_class)\n",
    "dataset, dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T15:36:18.908661600Z",
     "start_time": "2024-05-16T15:36:04.004338200Z"
    }
   },
   "id": "9a3e4898f36d1351",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock return: -1.87%, trend: Down\n",
      "Stock return: -0.15%, trend: Down\n",
      "Stock return: -1.05%, trend: Down\n",
      "Stock return: 0.57%, trend: Up\n",
      "Stock return: -0.37%, trend: Down\n",
      "Stock return: -0.86%, trend: Down\n",
      "Stock return: 2.05%, trend: Up\n",
      "Stock return: -0.08%, trend: Down\n",
      "Stock return: 2.44%, trend: Up\n",
      "Stock return: 2.64%, trend: Up\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "\tprint(f\"Stock return: {dataset[i].returns[i].item() * 100:.2f}%, trend: {['Down', 'Up'][int(dataset[i].y[i].item())]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T15:36:24.930079Z",
     "start_time": "2024-05-16T15:36:18.902238600Z"
    }
   },
   "id": "57da3cdd002c63a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1068, Test dataset: 119\n"
     ]
    }
   ],
   "source": [
    "train_part = .9\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset, test_dataset = dataset[:int(train_part * len(dataset))], dataset[int(train_part * len(dataset)):]\n",
    "print(f\"Train dataset: {len(train_dataset)}, Test dataset: {len(test_dataset)}\")\n",
    "train_dataloader, test_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True), DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T15:36:26.126784400Z",
     "start_time": "2024-05-16T15:36:24.924762700Z"
    }
   },
   "id": "c19ec7f01b687546",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "The previously implemented models are used, trained using the training dataset and the Adam optimizer. The `weight_decay` parameter is used for L2 regularization, to follow the T-GCN papers methodology. The loss is calculated using the Binary Cross Entropy (BCE) loss function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c397fdede6ac75ca"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "TGCN(\n  (cells): ModuleList(\n    (0): TGCNCell(\n      (gcn): GAT(\n        (convs): ModuleList(\n          (0): GATv2Conv(8, 16, heads=1)\n          (1): GATv2Conv(16, 16, heads=1)\n        )\n      )\n      (lin_u): Linear(in_features=40, out_features=16, bias=True)\n      (lin_r): Linear(in_features=40, out_features=16, bias=True)\n      (lin_c): Linear(in_features=40, out_features=16, bias=True)\n    )\n    (1): TGCNCell(\n      (gcn): GAT(\n        (convs): ModuleList(\n          (0-1): 2 x GATv2Conv(16, 16, heads=1)\n        )\n      )\n      (lin_u): Linear(in_features=48, out_features=16, bias=True)\n      (lin_r): Linear(in_features=48, out_features=16, bias=True)\n      (lin_c): Linear(in_features=48, out_features=16, bias=True)\n    )\n  )\n  (out): Sequential(\n    (0): Linear(in_features=16, out_features=1, bias=True)\n    (1): Identity()\n  )\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels, out_channels, hidden_size, layers_nb, dropout = dataset[0].x.shape[-2], 1, 16, 2, .3\n",
    "model = TGCN(in_channels, out_channels, hidden_size, layers_nb)\n",
    "\n",
    "lr, weight_decay, num_epochs = 0.005, 1e-5, 100\n",
    "\t\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T15:36:26.547451100Z",
     "start_time": "2024-05-16T15:36:26.117785500Z"
    }
   },
   "id": "b1e80dd2460f76c8",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 100/100 [3:17:13<00:00, 118.33s/it, Batch=100.0%] \n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_dataloader, test_dataloader, num_epochs, \"UpDownTrend\", measure_acc=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T19:13:50.861679400Z",
     "start_time": "2024-05-16T15:56:37.496605300Z"
    }
   },
   "id": "b9a14e708ed5751a",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"models/saved_models/UpDownTrend_{model.__class__.__name__}.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T19:15:30.829963100Z",
     "start_time": "2024-05-16T19:15:30.723956700Z"
    }
   },
   "id": "d999836db215a954",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TGCN(in_channels, out_channels, hidden_size, layers_nb)\n",
    "model.load_state_dict(torch.load(f\"models/saved_models/UpDownTrend_{model.__class__.__name__}.pt\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T19:15:30.906277100Z",
     "start_time": "2024-05-16T19:15:30.832958Z"
    }
   },
   "id": "ff388c5df2a11e",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc8d5b036ec061a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results on train data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a48317a251f7ffb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 77.7%\n",
      "Train confusion matrix:\n",
      "[[33011 14409]\n",
      " [ 9268 49612]]\n"
     ]
    }
   ],
   "source": [
    "full_train_data = next(iter(DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)))\n",
    "acc, cm = measure_accuracy(model, full_train_data), get_confusion_matrix(model, full_train_data)\n",
    "\n",
    "print(f\"Train accuracy: {acc * 100:.1f}%\\nTrain confusion matrix:\\n{cm}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T11:33:27.904906100Z",
     "start_time": "2024-05-16T11:30:58.903941900Z"
    }
   },
   "id": "8023d2cf30e5bed9",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results on test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a686b22706591186"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 77.0%\n",
      "Test confusion matrix:\n",
      "[[ 912  418]\n",
      " [ 249 1621]]\n"
     ]
    }
   ],
   "source": [
    "acc, cm = measure_accuracy(model, next(iter(train_dataloader))), get_confusion_matrix(model, next(iter(train_dataloader)))\n",
    "\n",
    "print(f\"Test accuracy: {acc * 100:.1f}%\\nTest confusion matrix:\\n{cm}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T11:33:36.072468100Z",
     "start_time": "2024-05-16T11:33:27.957343900Z"
    }
   },
   "id": "e35e29096a020f59",
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
