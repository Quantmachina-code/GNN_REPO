{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-16T08:11:31.217886600Z",
     "start_time": "2024-05-16T08:11:31.175247700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from datasets.SP100Stocks import SP100Stocks\n",
    "from notebooks.models import TGCN, A3TGCN, DCGNN, train, measure_accuracy, get_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Buy or Sell? Stocks classifier\n",
    "The goal of this task is to classify stocks into buy or sell categories based on past performance. The model should predict if the next day is higher or lower than the current day, with past 5 weeks of knowledge. There are no patterns in stock movements, so neural networks have a hard time forecasting the next timestamps. The intuition is that they can, however, capture up/down trends."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c131dcf02f1f4676"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the data\n",
    "The data from the custom PyG dataset for forecasting is loaded into a PyTorch dataloader.\n",
    "A \"transform\" is applied to change the targets `y` of the dataset to a binary buy/sell class instead of the close price. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d226612314d578cf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def future_close_price_to_buy_sell_class(sample: Data):\n",
    "\t\"\"\"\n",
    "\tTransforms the target y to a binary buy (1) if the stock return two weeks ahead was higher that the average market return, else sell (0)\n",
    "\t:param sample: Data sample\n",
    "\t:return: The transformed sample\n",
    "\t\"\"\"\n",
    "\tmarket_return = ((sample.close_price_y[:, -1] - sample.close_price[:, -1]) / sample.close_price[:, -1]).mean()\n",
    "\tsample.returns = ((sample.close_price_y[:, -1] - sample.close_price[:, -1]) / sample.close_price[:, -1]).unsqueeze(1)\n",
    "\tsample.market_return = market_return\n",
    "\t## Multi-class trend classification (down, constant, up)\n",
    "\t# constant_trend_threshold = .01\n",
    "\t# is_down_trend = (sample.returns < -constant_trend_threshold)\n",
    "\t# is_constant_trend = ((sample.returns >= -constant_trend_threshold) * (sample.returns <= constant_trend_threshold))\n",
    "\t# is_up_trend = (sample.returns > constant_trend_threshold)\n",
    "\t# sample.y = (is_constant_trend + is_up_trend * 2).long().squeeze(1)\n",
    "\t# return sample\n",
    "\t# Binary trend classification (down, up)\n",
    "\tsample.y = (sample.returns >= 0).float()\n",
    "\treturn sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T08:44:56.923704700Z",
     "start_time": "2024-05-16T08:44:56.911166Z"
    }
   },
   "id": "5e3cb82e3e8111d2",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(SP100Stocks(1182),\n Data(x=[100, 8, 25], edge_index=[2, 524], y=[100, 1], edge_weight=[524], close_price=[100, 25], close_price_y=[100, 10], returns=[100, 1], market_return=0.019632836803793907))"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks_ahead = 2\n",
    "\n",
    "dataset = SP100Stocks(future_window=weeks_ahead * 5, force_reload=True, transform=future_close_price_to_buy_sell_class)\n",
    "dataset, dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T08:45:00.553940300Z",
     "start_time": "2024-05-16T08:44:58.378701100Z"
    }
   },
   "id": "9a3e4898f36d1351",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock return: 1.08%, trend: Up\n",
      "Stock return: -1.74%, trend: Down\n",
      "Stock return: -0.38%, trend: Down\n",
      "Stock return: 1.92%, trend: Up\n",
      "Stock return: -0.96%, trend: Down\n",
      "Stock return: 5.56%, trend: Up\n",
      "Stock return: -0.17%, trend: Down\n",
      "Stock return: -5.16%, trend: Down\n",
      "Stock return: -4.91%, trend: Down\n",
      "Stock return: 2.96%, trend: Up\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "\t# print(f\"Stock return: {dataset[i].returns[i].item() * 100:.2f}%, trend: {['Down', 'Constant', 'Up'][dataset[i].y[i].item()]}\")\n",
    "\tprint(f\"Stock return: {dataset[i].returns[i].item() * 100:.2f}%, trend: {['Down', 'Up'][int(dataset[i].y[i].item())]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T08:45:15.166349300Z",
     "start_time": "2024-05-16T08:45:05.264359900Z"
    }
   },
   "id": "57da3cdd002c63a",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1063, Test dataset: 119\n"
     ]
    }
   ],
   "source": [
    "train_part = .9\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset, test_dataset = dataset[:int(train_part * len(dataset))], dataset[int(train_part * len(dataset)):]\n",
    "print(f\"Train dataset: {len(train_dataset)}, Test dataset: {len(test_dataset)}\")\n",
    "train_dataloader, test_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True), DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T09:21:55.279625900Z",
     "start_time": "2024-05-16T09:21:53.587449200Z"
    }
   },
   "id": "c19ec7f01b687546",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "The previously implemented models are used, trained using the training dataset and the Adam optimizer. The `weight_decay` parameter is used for L2 regularization, to follow the T-GCN papers methodology. The loss is calculated using the Binary Cross Entropy (BCE) loss function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c397fdede6ac75ca"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "TGCN(\n  (cells): ModuleList(\n    (0): TGCNCell(\n      (gcn): GAT(\n        (convs): ModuleList(\n          (0): GATv2Conv(8, 16, heads=1)\n          (1): GATv2Conv(16, 16, heads=1)\n        )\n      )\n      (lin_u): Linear(in_features=40, out_features=16, bias=True)\n      (lin_r): Linear(in_features=40, out_features=16, bias=True)\n      (lin_c): Linear(in_features=40, out_features=16, bias=True)\n    )\n    (1): TGCNCell(\n      (gcn): GAT(\n        (convs): ModuleList(\n          (0-1): 2 x GATv2Conv(16, 16, heads=1)\n        )\n      )\n      (lin_u): Linear(in_features=48, out_features=16, bias=True)\n      (lin_r): Linear(in_features=48, out_features=16, bias=True)\n      (lin_c): Linear(in_features=48, out_features=16, bias=True)\n    )\n  )\n  (out): Sequential(\n    (0): Linear(in_features=16, out_features=1, bias=True)\n    (1): Identity()\n  )\n)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels, out_channels, hidden_size, layers_nb, dropout = dataset[0].x.shape[-2], 1, 16, 2, .3\n",
    "model = TGCN(in_channels, out_channels, hidden_size, layers_nb)\n",
    "\n",
    "lr, weight_decay, num_epochs = 0.005, 1e-5, 64\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()  # for multi-class classification\n",
    "criterion = nn.BCEWithLogitsLoss()  # for binary up/down classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T09:21:55.662269600Z",
     "start_time": "2024-05-16T09:21:55.277162900Z"
    }
   },
   "id": "b1e80dd2460f76c8",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 64/64 [2:09:03<00:00, 120.99s/it, Batch=100.0%]  \n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_dataloader, test_dataloader, num_epochs, \"BuyOrSell\", measure_acc=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T11:30:58.908075800Z",
     "start_time": "2024-05-16T09:21:55.656914500Z"
    }
   },
   "id": "b9a14e708ed5751a",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc8d5b036ec061a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results on train data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a48317a251f7ffb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 77.7%\n",
      "Train confusion matrix:\n",
      "[[33011 14409]\n",
      " [ 9268 49612]]\n"
     ]
    }
   ],
   "source": [
    "full_train_data = next(iter(DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)))\n",
    "acc, cm = measure_accuracy(model, full_train_data), get_confusion_matrix(model, full_train_data)\n",
    "\n",
    "print(f\"Train accuracy: {acc * 100:.1f}%\\nTrain confusion matrix:\\n{cm}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T11:33:27.904906100Z",
     "start_time": "2024-05-16T11:30:58.903941900Z"
    }
   },
   "id": "8023d2cf30e5bed9",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results on test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a686b22706591186"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 77.0%\n",
      "Test confusion matrix:\n",
      "[[ 912  418]\n",
      " [ 249 1621]]\n"
     ]
    }
   ],
   "source": [
    "acc, cm = measure_accuracy(model, next(iter(train_dataloader))), get_confusion_matrix(model, next(iter(train_dataloader)))\n",
    "\n",
    "print(f\"Test accuracy: {acc * 100:.1f}%\\nTest confusion matrix:\\n{cm}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T11:33:36.072468100Z",
     "start_time": "2024-05-16T11:33:27.957343900Z"
    }
   },
   "id": "e35e29096a020f59",
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
