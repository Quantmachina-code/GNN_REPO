{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:16:36.446955800Z",
     "start_time": "2024-05-07T06:16:36.398550100Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from datasets.SP100Stocks import SP100Stocks\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.nn import GCNConv, GAE\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-d200f91fff6e260\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-d200f91fff6e260\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T05:54:04.747487Z",
     "start_time": "2024-05-07T05:54:04.728727300Z"
    }
   },
   "id": "8488f1be3d432f94",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stock prices forecasting\n",
    "The goal of this task is to predict the (normalized) price at the timestep $t+1$ for each stock in the S&P 100 index. For this task, a Temporal Graph Convolutional Network ([T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction](https://arxiv.org/pdf/1811.05320)) is used. It consists of a GCN encoder followed by a GRU decoder. The encoder is used to learn the representation of the graph at each timestep, while the decoder is used to predict the variation at the next timestep."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ba91ac06624fe6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the data\n",
    "The data from the custom PyG dataset for forecasting is loaded into a PyTorch dataloader."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81851c4abd6dea08"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(SP100Stocks(1208),\n Data(x=[100, 7, 25], edge_index=[2, 2460], y=[100, 1], edge_weight=[2460], close_price=[100, 25], close_price_y=[100, 1]))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = SP100Stocks()\n",
    "dataset, dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T05:54:13.207219200Z",
     "start_time": "2024-05-07T05:54:10.556141300Z"
    }
   },
   "id": "c98cc6a96a3b206c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1087, Test dataset: 121\n"
     ]
    }
   ],
   "source": [
    "train_part = .9\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset, test_dataset = dataset[:int(train_part * len(dataset))], dataset[int(train_part * len(dataset)):]\n",
    "print(f\"Train dataset: {len(train_dataset)}, Test dataset: {len(test_dataset)}\")\n",
    "train_dataloader, test_dataloader = DataLoader(train_dataset, batch_size=batch_size), DataLoader(test_dataset, batch_size=batch_size // 4, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T05:54:14.544390100Z",
     "start_time": "2024-05-07T05:54:12.670047300Z"
    }
   },
   "id": "4680edb77d8d7970",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Temporal Graph Convolutional Network Model\n",
    "The TGCN from the paper is implemented using PyTorch. The model encodes the graph nodes with a two-layer GCN, and then decodes the hidden state with a GRU."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9f08efa96a12588"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tSimple two layers GCN model.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, in_channels: int, layer_sizes: list[int] = None):\n",
    "\t\tsuper(GCN, self).__init__()\n",
    "\t\tlayer_sizes = layer_sizes or [32, 16]\n",
    "\t\tself.convs = nn.ModuleList([\n",
    "\t\t\tGCNConv(in_channels, layer_sizes[0]),\n",
    "\t\t] + [\n",
    "\t\t\tGCNConv(layer_sizes[i], layer_sizes[i + 1]) for i in range(len(layer_sizes) - 1)\n",
    "\t\t])\n",
    "\t\t\t\t\t\t\t   \t\t\n",
    "\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> torch.tensor:\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms a forward pass on the GCN model.\n",
    "\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb)\n",
    "\t\t:param edge_index: The edge index of the graph A (2, Edges_nb) \n",
    "\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n",
    "\t\t:return: The hidden state of the GCN h_t (Nodes_nb, Hidden_size)\n",
    "\t\t\"\"\"\n",
    "\t\tfor conv in self.convs:\n",
    "\t\t\tx = F.relu(conv(x, edge_index, edge_weight))\n",
    "\t\treturn x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:52:09.802351900Z",
     "start_time": "2024-05-07T06:52:09.772263100Z"
    }
   },
   "id": "f4c2e175b3cfd45f",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TGCNCell(nn.Module):\n",
    "\t\"\"\"\n",
    "\tT-GCN Cell for one timestep, from https://arxiv.org/pdf/1811.05320.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, in_channels: int, hidden_size: int):\n",
    "\t\tsuper(TGCNCell, self).__init__()\n",
    "\t\tself.gcn = GCN(in_channels, [hidden_size, hidden_size])\n",
    "\t\tself.lin_u = nn.Linear(2 * hidden_size, hidden_size)\n",
    "\t\tself.lin_r = nn.Linear(2 * hidden_size, hidden_size)\n",
    "\t\tself.lin_c = nn.Linear(2 * hidden_size, hidden_size)\n",
    "\t\t\n",
    "\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor, h: torch.tensor) -> tuple[torch.tensor, torch.tensor]:\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms a forward pass on a single TGCN cell (GCN + GRU).\n",
    "\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb)\n",
    "\t\t:param edge_index: The edge index of the graph A (2, Edges_nb) \n",
    "\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n",
    "\t\t:param h: The hidden state of the GRU h_{t-1} (Nodes_nb, Hidden_size)\n",
    "\t\t:return: The hidden state of the GRU h_t (Nodes_nb, Hidden_size)\n",
    "\t\t\"\"\"\n",
    "\t\tx = F.sigmoid(self.gcn(x, edge_index, edge_weight))  # f(A,X_t), Eq. 2\n",
    "\t\tu = F.sigmoid(self.lin_u(torch.cat([x, h], dim=-1)))  # u_t, Eq. 3\n",
    "\t\tr = F.sigmoid(self.lin_r(torch.cat([x, h], dim=-1)))  # r_t,  Eq. 4\n",
    "\t\tc = F.tanh(self.lin_c(torch.cat([x, r * h], dim=-1)))  # c_t, Eq. 5\n",
    "\n",
    "\t\treturn u * h + (1 - u) * c  # h_t, Eq. 6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:49:59.107056200Z",
     "start_time": "2024-05-07T06:49:59.082123400Z"
    }
   },
   "id": "cc89b3ec38fd04b",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TGCN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tT-GCN model from https://arxiv.org/pdf/1811.05320.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, in_channels: int, out_channels: int, hidden_size: int):\n",
    "\t\tsuper(TGCN, self).__init__()\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.cell = TGCNCell(in_channels, hidden_size)\n",
    "\t\tself.out = nn.Linear(hidden_size, out_channels)\n",
    "\t\t\n",
    "\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> torch.tensor:\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms a forward pass on the TGCN model.\n",
    "\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb, SeqLength)\n",
    "\t\t:param edge_index: The edge index of the graph A (2, Edges_nb) \n",
    "\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n",
    "\t\t:return: The hidden state of the GRU h_t (Nodes_nb, Hidden_size)\n",
    "\t\t\"\"\"\n",
    "\t\th = torch.zeros(x.shape[0], self.hidden_size)\n",
    "\t\tfor t in range(x.shape[-1]):\n",
    "\t\t\th = self.cell(x[:, :, t], edge_index, edge_weight, h)\n",
    "\t\treturn self.out(h)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:49:59.185993600Z",
     "start_time": "2024-05-07T06:49:59.111237200Z"
    }
   },
   "id": "d1bfa7448d43bfab",
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "The model is trained using the training dataset and the Adam optimizer. The `weight_decay` parameter is used for L2 regularization, to follow the paper methodology. The loss is calculated using the Mean Squared Error (MSE) loss function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e13861cd3aeefb7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(model: nn.Module, optimizer: optim.Optimizer, criterion: nn.Module, train_dataloader: DataLoader, test_dataloader: DataLoader, num_epochs: int) -> tuple[list, list]:\n",
    "\twriter = SummaryWriter(f'runs/PriceForecasting_{datetime.now().strftime(\"%d_%m_%Hh%M\")}')\n",
    "\tfor epoch in (pbar := trange(num_epochs, desc=\"Epochs\")):\n",
    "\t\tfor idx, data in enumerate(train_dataloader):\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tout = model(data.x, data.edge_index, data.edge_weight)\n",
    "\t\t\tloss = criterion(out, data.y)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tpbar.set_postfix({\"Loss\": loss.item(), \"Batch\": f\"{idx / len(train_dataloader) * 100:.1f}%\"})\n",
    "\t\t\twriter.add_scalar(\"Loss/Train Loss\", loss.item(), epoch * len(train_dataloader) + idx)\n",
    "\t\tfor idx, data in enumerate(test_dataloader):\n",
    "\t\t\tout = model(data.x, data.edge_index, data.edge_weight)\n",
    "\t\t\tloss = criterion(out, data.y)\n",
    "\t\t\twriter.add_scalar(\"Loss/Test Loss\", loss.item(), epoch * len(test_dataloader) + idx)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:49:59.215015400Z",
     "start_time": "2024-05-07T06:49:59.147364400Z"
    }
   },
   "id": "c6f5a91266af740",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "TGCN(\n  (cell): TGCNCell(\n    (gcn): GCN(\n      (convs): ModuleList(\n        (0): GCNConv(7, 32)\n        (1): GCNConv(32, 32)\n      )\n    )\n    (lin_u): Linear(in_features=64, out_features=32, bias=True)\n    (lin_r): Linear(in_features=64, out_features=32, bias=True)\n    (lin_c): Linear(in_features=64, out_features=32, bias=True)\n  )\n  (out): Linear(in_features=32, out_features=1, bias=True)\n)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels, out_channels, hidden_size = dataset[0].x.shape[-2], 1, 32\n",
    "model = TGCN(in_channels, out_channels, hidden_size)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:49:59.567614600Z",
     "start_time": "2024-05-07T06:49:59.198098700Z"
    }
   },
   "id": "a0f381a467189402",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lr, weight_decay, num_epochs = 0.005, 1e-5, 12\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:49:59.568717300Z",
     "start_time": "2024-05-07T06:49:59.522665500Z"
    }
   },
   "id": "4d3ce94cb5d4b73d",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train(model, optimizer, criterion, train_dataloader, test_dataloader, num_epochs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55ce79d10dbcf97d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "The model tries to forecast the variations one timestep ahead for four stocks. The real values are plotted against the forecasted values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32f9bab3545efa79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results on train data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c5fa2c4da8a530e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_predictions = np.array([\n",
    "\tmodel(g.x, g.edge_index, g.edge_weight).detach().numpy() for g in train_dataloader\n",
    "]).reshape((len(train_dataloader) * train_dataloader.batch_size, -1))\n",
    "train_targets = np.array([g.y.numpy() for g in train_dataloader]).reshape((len(train_dataloader) * train_dataloader.batch_size, -1))\n",
    "\n",
    "MSE = np.mean((train_predictions - train_targets) ** 2)\n",
    "RMSE = np.sqrt(MSE)\n",
    "MAE = np.mean(np.abs(train_predictions - train_targets))\n",
    "\n",
    "print(f\"Mean Squared Error: {MSE:.4f}, Root Mean Squared Error: {RMSE:.4f}, Mean Absolute Error: {MAE:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:50:18.127760Z",
     "start_time": "2024-05-07T06:50:18.032375600Z"
    }
   },
   "id": "6b568ae9238faa39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "stocks_idx = np.random.choice(train_predictions.shape[1], 4)\n",
    "n = 200\n",
    "for idx, stock_idx in enumerate(stocks_idx):\n",
    "\taxs[idx // 2, idx % 2].plot(train_targets[:, stock_idx][n:2 * n], label=\"Real\")\n",
    "\taxs[idx // 2, idx % 2].plot(train_predictions[:, stock_idx][n:2 * n], label=\"Forecast\")\n",
    "\taxs[idx // 2, idx % 2].legend()\n",
    "\taxs[idx // 2, idx % 2].set_xticks(range(0, n, 5), minor=True)\n",
    "\taxs[idx // 2, idx % 2].grid(which='minor', alpha=0.2)\n",
    "\taxs[idx // 2, idx % 2].grid(which='major', alpha=0.5)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-07T06:50:18.037110200Z"
    }
   },
   "id": "348e88b86cfd540e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results on test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3856ffa1e2f6012d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_predictions = np.array([\n",
    "\tmodel(g.x, g.edge_index, g.edge_weight).detach().numpy() for g in test_dataloader\n",
    "]).reshape((len(test_dataloader) * test_dataloader.batch_size, -1))\n",
    "test_targets = np.array([g.y.numpy() for g in test_dataloader]).reshape((len(test_dataloader) * test_dataloader.batch_size, -1))\n",
    "\n",
    "MSE = np.mean((test_predictions - test_targets)**2)\n",
    "RMSE = np.sqrt(MSE)\n",
    "MAE = np.mean(np.abs(test_predictions - test_targets))\n",
    "\n",
    "print(f\"Mean Squared Error: {MSE:.4f}, Root Mean Squared Error: {RMSE:.4f}, Mean Absolute Error: {MAE:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-07T06:50:18.042450200Z"
    }
   },
   "id": "490e065ba3fe59ea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "stocks_idx = np.random.choice(test_targets.shape[1], 4)\n",
    "for idx, stock_idx in enumerate(stocks_idx):\n",
    "\taxs[idx // 2, idx % 2].plot(test_targets[:, stock_idx], label=\"Real\")\n",
    "\taxs[idx // 2, idx % 2].plot(test_predictions[:, stock_idx], label=\"Forecast\")\n",
    "\taxs[idx // 2, idx % 2].legend()\n",
    "\taxs[idx // 2, idx % 2].set_xticks(range(0, len(test_dataloader) * test_dataloader.batch_size, 5), minor=True)\n",
    "\taxs[idx // 2, idx % 2].grid(which='minor', alpha=0.2)\n",
    "\taxs[idx // 2, idx % 2].grid(which='major', alpha=0.5)\n",
    "\t\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-07T06:50:18.047801100Z"
    }
   },
   "id": "5b60a13d297d5004",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DGAE(nn.Module):\n",
    "\t\"\"\"\n",
    "\tDual Graph Autoencoder model from https://www.sciencedirect.com/science/article/abs/pii/S0950705121008261.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, in_channels: int, hidden_channels: list[int] = None):\n",
    "\t\tsuper(DGAE, self).__init__()\n",
    "\t\thidden_channels = hidden_channels or [32, 16, 8]\n",
    "\t\tself.gae = GAE(\n",
    "\t\t\tGCN(in_channels, hidden_channels), \n",
    "\t\t)\n",
    "\t\tself.feat_decoder = GCN(hidden_channels[-1], hidden_channels[::-1][1:] + [in_channels])\n",
    "\t\t\t\n",
    "\tdef encode(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> torch.tensor:\n",
    "\t\t\"\"\"\n",
    "\t\tEncodes the input graph into a latent representation.\n",
    "\t\t:param x: The feature matrix of the graph X (Nodes_nb, Features_nb)\n",
    "\t\t:param edge_index: The edge index of the graph A (2, Edges_nb) \n",
    "\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n",
    "\t\t:return: The encoded latent representation of the graph z (Nodes_nb, Hidden_size)\n",
    "\t\t\"\"\"\n",
    "\t\treturn self.gae.encode(x, edge_index, edge_weight)\n",
    "\t\n",
    "\tdef decode(self, z: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> tuple[torch.tensor, torch.tensor]:\n",
    "\t\t\"\"\"\n",
    "\t\tDecodes the latent representation into the feature matrix.\n",
    "\t\t:param z: The encoded latent representation of the graph z (Nodes_nb, Hidden_size)\n",
    "\t\t:param edge_index: The edge index of the graph A (2, Edges_nb) \n",
    "\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n",
    "\t\t:return: The decoded adjacency matrix of the graph A (Nodes_nb, Nodes_nb) and the decoded feature matrix of the graph X' (Nodes_nb, Features_nb)\n",
    "\t\t\"\"\"\n",
    "\t\treturn self.gae.decode(z), self.feat_decoder(z, edge_index, edge_weight)\n",
    "\t\n",
    "\tdef feat_recon_loss(self, x: torch.tensor, z: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> torch.tensor:\n",
    "\t\t\"\"\"\n",
    "\t\tCalculates the feature matrix reconstruction loss.\n",
    "\t\t:param x: The original feature matrix of the graph X (Nodes_nb, Features_nb)\n",
    "\t\t:param z: The encoded latent representation of the graph z (Nodes_nb, Hidden_size)\n",
    "\t\t:param edge_index: The edge index of the graph A (2, Edges_nb)\n",
    "\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n",
    "\t\t:return: The feature matrix reconstruction loss\n",
    "\t\t\"\"\"\n",
    "\t\treturn F.mse_loss(self.feat_decoder(z, edge_index, edge_weight), x)\n",
    "\t\n",
    "\tdef loss(self, x: torch.tensor, z: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor, lam: float = .5) -> torch.tensor:\n",
    "\t\t\"\"\"\n",
    "\t\tCalculates the loss of the DGAE model.\n",
    "\t\t:param x: The original feature matrix of the graph X (Nodes_nb, Features_nb)\n",
    "\t\t:param z: The encoded latent representation of the graph z (Nodes_nb, Hidden_size)\n",
    "\t\t:param edge_index: The edge index of the graph A (2, Edges_nb)\n",
    "\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n",
    "\t\t:param lam: The lambda parameter for feature matrix loss\n",
    "\t\t:return: The loss of the DGAE model\n",
    "\t\t\"\"\"\n",
    "\t\treturn self.gae.recon_loss(z, edge_index) + lam / 2 * self.feat_recon_loss(x, z, edge_index, edge_weight)\n",
    "\t\n",
    "\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> tuple[torch.tensor, torch.tensor]:\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms a forward pass on the DGAE model.\n",
    "\t\t:param x: The feature matrix of the graph X (Nodes_nb, Features_nb)\n",
    "\t\t:param edge_index: The edge index of the graph A (2, Edges_nb)\n",
    "\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n",
    "\t\t:return: The decoded adjacency matrix of the graph A (Nodes_nb, Nodes_nb) and the decoded feature matrix of the graph X' (Nodes_nb, Features_nb)\n",
    "\t\t\"\"\"\n",
    "\t\tz = self.encode(x, edge_index, edge_weight)\n",
    "\t\treturn self.decode(z, edge_index, edge_weight)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:52:14.947977300Z",
     "start_time": "2024-05-07T06:52:14.911079100Z"
    }
   },
   "id": "c91269a787cc801a",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TGCNCellDGAE(nn.Module):\n",
    "\t\"\"\"\n",
    "\tT-GCN Cell for one timestep using DGAE, from https://arxiv.org/pdf/1811.05320.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, in_channels: int, hidden_size: int):\n",
    "\t\tsuper(TGCNCellDGAE, self).__init__()\n",
    "\t\tself.dgae = DGAE(in_channels, [4 * hidden_size, 2 * hidden_size, hidden_size])\n",
    "\t\tself.lin_u = nn.Linear(2 * hidden_size, hidden_size)\n",
    "\t\tself.lin_r = nn.Linear(2 * hidden_size, hidden_size)\n",
    "\t\tself.lin_c = nn.Linear(2 * hidden_size, hidden_size)\n",
    "\t\t\n",
    "\t\tself.losses = []\n",
    "\n",
    "\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor, h: torch.tensor) -> tuple[\n",
    "\t\ttorch.tensor, torch.tensor]:\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms a forward pass on a single TGCN cell (GCN + GRU).\n",
    "\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb)\n",
    "\t\t:param edge_index: The edge index of the graph A (2, Edges_nb) \n",
    "\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n",
    "\t\t:param h: The hidden state of the GRU h_{t-1} (Nodes_nb, Hidden_size)\n",
    "\t\t:return: The hidden state of the GRU h_t (Nodes_nb, Hidden_size)\n",
    "\t\t\"\"\"\n",
    "\t\tz = self.dgae.encode(x, edge_index, edge_weight)\n",
    "\t\tself.losses.append(self.dgae.loss(x, z, edge_index, edge_weight))\n",
    "\t\tx = F.relu(z)  # f(A,X_t), Eq. 2\n",
    "\t\tu = F.sigmoid(self.lin_u(torch.cat([x, h], dim=-1)))  # u_t, Eq. 3\n",
    "\t\tr = F.sigmoid(self.lin_r(torch.cat([x, h], dim=-1)))  # r_t,  Eq. 4\n",
    "\t\tc = F.tanh(self.lin_c(torch.cat([x, r * h], dim=-1)))  # c_t, Eq. 5\n",
    "\n",
    "\t\treturn u * h + (1 - u) * c  # h_t, Eq. 6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:52:14.990486700Z",
     "start_time": "2024-05-07T06:52:14.953905900Z"
    }
   },
   "id": "714991538432fbca",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TGCNDGAE(nn.Module):\n",
    "\t\"\"\"\n",
    "\tT-GCN model from https://arxiv.org/pdf/1811.05320.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, in_channels: int, out_channels: int, hidden_size: int):\n",
    "\t\tsuper(TGCNDGAE, self).__init__()\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.cell = TGCNCellDGAE(in_channels, hidden_size)\n",
    "\t\tself.out = nn.Linear(hidden_size, out_channels)\n",
    "\t\t\t\n",
    "\tdef loss(self, y: torch.tensor, y_hat: torch.tensor, a: float = 1., b: float = 1.) -> torch.tensor:\n",
    "\t\t\"\"\"\n",
    "\t\tCalculates the loss of the TGCN model.\n",
    "\t\t:param y: The real values of the graph Y_t (Nodes_nb, Features_nb)\n",
    "\t\t:param y_hat: The predicted values of the graph Y'_t (Nodes_nb, Features_nb)\n",
    "\t\t:param a: The parameter for the DGAE loss\n",
    "\t\t:param b: The parameter for the MSE loss\n",
    "\t\t:return: The loss of the TGCN model\n",
    "\t\t\"\"\"\n",
    "\t\tdgae_loss = torch.stack(self.cell.losses).mean()\n",
    "\t\tself.cell.losses = []\n",
    "\t\treturn a * dgae_loss + b * F.mse_loss(y, y_hat)\n",
    "\t\n",
    "\tdef forward(self, x: torch.tensor, edge_index: torch.tensor, edge_weight: torch.tensor) -> torch.tensor:\n",
    "\t\t\"\"\"\n",
    "\t\tPerforms a forward pass on the TGCN model.\n",
    "\t\t:param x: The feature matrix of the graph X_t (Nodes_nb, Features_nb, SeqLength)\n",
    "\t\t:param edge_index: The edge index of the graph A (2, Edges_nb) \n",
    "\t\t:param edge_weight: The edge weight of the graph (Edges_nb,)\n",
    "\t\t:return: The hidden state of the GRU h_t (Nodes_nb, Hidden_size)\n",
    "\t\t\"\"\"\n",
    "\t\th = torch.zeros(x.shape[0], self.hidden_size)\n",
    "\t\tfor t in range(x.shape[-1]):\n",
    "\t\t\th = self.cell(x[:, :, t], edge_index, edge_weight, h)\n",
    "\t\treturn self.out(h)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:52:15.009530900Z",
     "start_time": "2024-05-07T06:52:14.995667900Z"
    }
   },
   "id": "7227d13662606dab",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "TGCNDGAE(\n  (cell): TGCNCellDGAE(\n    (dgae): DGAE(\n      (gae): GAE(\n        (encoder): GCN(\n          (convs): ModuleList(\n            (0): GCNConv(7, 128)\n            (1): GCNConv(128, 64)\n            (2): GCNConv(64, 32)\n          )\n        )\n        (decoder): InnerProductDecoder()\n      )\n      (feat_decoder): GCN(\n        (convs): ModuleList(\n          (0): GCNConv(32, 64)\n          (1): GCNConv(64, 128)\n          (2): GCNConv(128, 7)\n        )\n      )\n    )\n    (lin_u): Linear(in_features=64, out_features=32, bias=True)\n    (lin_r): Linear(in_features=64, out_features=32, bias=True)\n    (lin_c): Linear(in_features=64, out_features=32, bias=True)\n  )\n  (out): Linear(in_features=32, out_features=1, bias=True)\n)"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels, out_channels, hidden_size = dataset[0].x.shape[-2], dataset[0].y.shape[-1], 32\n",
    "model = TGCNDGAE(in_channels, out_channels, hidden_size)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:52:15.712221700Z",
     "start_time": "2024-05-07T06:52:15.011612700Z"
    }
   },
   "id": "6898f0f3653994bf",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lr, weight_decay, num_epochs = 0.005, 1e-5, 16\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:52:15.728938200Z",
     "start_time": "2024-05-07T06:52:15.714831100Z"
    }
   },
   "id": "353a15902a3b9d34",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(model: nn.Module, optimizer: optim.Optimizer, train_dataloader: DataLoader, test_dataloader: DataLoader, num_epochs: int) -> tuple[list, list]:\n",
    "\twriter = SummaryWriter(f'runs/PriceForecasting_{datetime.now().strftime(\"%d_%m_%Hh%M\")}')\n",
    "\tfor epoch in (pbar := trange(num_epochs, desc=\"Epochs\")):\n",
    "\t\tfor idx, data in enumerate(train_dataloader):\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tout = model(data.x, data.edge_index, data.edge_weight)\n",
    "\t\t\tloss = model.loss(data.y, out)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tpbar.set_postfix({\"Loss\": loss.item(), \"Batch\": f\"{idx / len(train_dataloader) * 100:.1f}%\"})\n",
    "\t\t\twriter.add_scalar(\"Loss/Train Loss\", loss.item(), epoch * len(train_dataloader) + idx)\n",
    "\t\tfor idx, data in enumerate(test_dataloader):\n",
    "\t\t\tout = model(data.x, data.edge_index, data.edge_weight)\n",
    "\t\t\tloss = model.loss(data.y, out)\n",
    "\t\t\twriter.add_scalar(\"Loss/Test Loss\", loss.item(), epoch * len(test_dataloader) + idx)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:52:15.732142400Z",
     "start_time": "2024-05-07T06:52:15.721268400Z"
    }
   },
   "id": "c04aa652d89d32a7",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/16 [03:29<?, ?it/s, Loss=3.8, Batch=47.1%] \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_dataloader, test_dataloader, num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T06:55:44.964294300Z",
     "start_time": "2024-05-07T06:52:15.731053400Z"
    }
   },
   "id": "f9c4dea6600a8ac2",
   "execution_count": 85
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
